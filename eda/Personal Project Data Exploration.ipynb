{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from boto.s3.connection import S3Connection\n",
    "import boto\n",
    "from boto.s3.key import Key\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "# import pyplot as plt\n",
    "import ast \n",
    "%matplotlib inline\n",
    "sys.path.insert(0,os.path.abspath('..'))\n",
    "from utils.credentials import access_key, secret_access_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('s3')\n",
    "\n",
    "conn = boto.s3.connect_to_region('us-east-2',\n",
    "       aws_access_key_id=access_key,\n",
    "       aws_secret_access_key=secret_access_key,\n",
    "       is_secure=True,\n",
    "       calling_format = boto.s3.connection.OrdinaryCallingFormat(),\n",
    "       )\n",
    "\n",
    "bucket = conn.get_bucket('persproj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[x.name for x in bucket.list() if '.json' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "s3 = boto3.resource('s3', aws_access_key_id=access_key,\n",
    "       aws_secret_access_key=secret_access_key)\n",
    "\n",
    "def read_json_from_s3(s3_bucket_name, file_name):\n",
    "    content_object = s3.Object(s3_bucket_name, file_name)\n",
    "    file_content = content_object.get()['Body'].read().decode('utf-8')\n",
    "    data = [json.loads(str(item)) for item in file_content.strip().split('\\n')]\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-7f16ab2d941a>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-7f16ab2d941a>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    %%time\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# user_df = pd.read_csv('s3://persproj/data/user_df.csv')\n",
    "# print('user_df finished')\n",
    "\n",
    "# business_df = pd.read_csv('s3://persproj/data/business_df.csv')\n",
    "# print('business_df finished')\n",
    "# checkin_df = pd.read_csv('s3://persproj/data/checkin_df.csv')\n",
    "# print('checkin_df finished')\n",
    "\n",
    "# tip_df = pd.read_csv('s3://persproj/data/tip_df.csv')\n",
    "# print('tip_df finished')\n",
    "# user_df = pd.read_csv('s3://persproj/data/user_df.csv')\n",
    "# print('user_df finished')\n",
    "\n",
    "# photo_df = pd.read_csv('s3://persproj/data/photo_df.csv')\n",
    "# print('photo_df finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read as JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business_df finished\n",
      "CPU times: user 3min 52s, sys: 10min 46s, total: 14min 38s\n",
      "Wall time: 42min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "review_df = read_json_from_s3('persproj','review.json')\n",
    "print('business_df finished' )\n",
    "# business_df = read_json_from_s3('persproj','business.json')\n",
    "# print('business_df finished' )\n",
    "\n",
    "'''\n",
    "\n",
    "FIRST TIME USE ONLY\n",
    "\n",
    "photo_df = read_json_from_s3('persproj','photo.json')\n",
    "print('photo_df finished' )\n",
    "\n",
    "business_df = read_json_from_s3('persproj','business.json')\n",
    "print('business_df finished' )\n",
    "checkin_df = read_json_from_s3('persproj','checkin.json')\n",
    "print('checkin_df finished' )\n",
    "photo_df = read_json_from_s3('persproj','photo.json')\n",
    "print('photo_df finished' )\n",
    "tip_df = read_json_from_s3('persproj','tip.json')\n",
    "print('tip_df finished' )\n",
    "user_df = read_json_from_s3('persproj','user.json')\n",
    "print('user_df finished' )\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6685900"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that all dfs are there\n",
    "dfs = [business_df, checkin_df, photo_df, tip_df, user_df]\n",
    "for df in dfs:\n",
    "    print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add everything to s3 bcket for easy access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 20s, sys: 1min 43s, total: 5min 4s\n",
      "Wall time: 28min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "review_df.to_csv('s3://persproj/data/review_df.csv', index=False)\n",
    "'''\n",
    "\n",
    "FIRST TIME USE ONLY\n",
    "\n",
    "business_df.to_csv('s3://persproj/data/business_df.csv', index=False)\n",
    "print('business_df finished')\n",
    "checkin_df.to_csv('s3://persproj/data/checkin_df.csv', index=False)\n",
    "print('checkin_df finished')\n",
    "photo_df.to_csv('s3://persproj/data/photo_df.csv', index=False)\n",
    "print('photo_df finished')\n",
    "tip_df.to_csv('s3://persproj/data/tip_df.csv', index=False)\n",
    "print('tip_df finished')\n",
    "user_df.to_csv('s3://persproj/data/user_df.csv', index=False)\n",
    "print('user_df finished')\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What kind of categories are most common ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df['categories_list'] = business_df['categories'].apply(lambda x: x.split(',') if not pd.isnull(x) else None,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_categories(series, series_type='list'):\n",
    "    count_dict = defaultdict(int)\n",
    "    if series_type == 'list':\n",
    "        for row in series:\n",
    "            if row is not None or not pd.isnull(row):\n",
    "                for item in row:\n",
    "                    count_dict[item.strip()] += 1\n",
    "    else:\n",
    "        for row in series:\n",
    "#             print(row, row is not None or pd.notna(row) or pd.notnull(row))\n",
    "            if not pd.isnull(row) or not pd.isna(row):\n",
    "                row = ast.literal_eval(row)\n",
    "                for item in row.items():\n",
    "                    count_dict[item[0].strip()] += 1\n",
    "    res_df = pd.DataFrame.from_dict(count_dict, orient='index')\n",
    "    res_df.rename(columns={0: 'count'}, inplace=1)\n",
    "    return res_df.sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = count_categories(business_df['categories_list'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df.head(50).plot.barh(y='count', figsize=(10,13))\n",
    "# plt.xticks(rotation=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not all restaurants contain the word \"Restaurant\"\n",
    "# we want to include all food related businesses\n",
    "\n",
    "food_df = (business_df[\n",
    "    (business_df['categories'].str.contains('Food',na=False)) |\n",
    "     (business_df['categories'].str.contains('Restaurant',na=False))|\n",
    "     (business_df['categories'].str.contains('Bar',na=False))\n",
    "])\n",
    "\n",
    "food_count_df = count_categories(food_df['categories_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "not_food_df = (business_df[\n",
    "    (~business_df['categories'].str.contains('Food',na=False)) &\n",
    "     (~business_df['categories'].str.contains('Restaurant',na=False))&\n",
    "     (~business_df['categories'].str.contains('Bar',na=False))\n",
    "])\n",
    "not_food_count_df = count_categories(not_food_df['categories_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check the non food categories to make sure there is no food related categories msising\n",
    "\n",
    "not_food_count_df[75:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(food_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df['stars'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df.groupby('state').count().plot.bar(y='address', figsize=(15,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.boxplot(boxprops= dict(linewidth=1.0, color='black')\n",
    "# , whiskerprops=dict(linestyle='-',linewidth=1.0, color='black'))\n",
    "\n",
    "food_df.boxplot(column='stars', by='state', figsize=(17,8),\n",
    "                boxprops=dict(linewidth=2.0, color='black'),\n",
    "                whiskerprops=dict(linestyle='-',linewidth=2.0, color='black'),\n",
    "                grid=False\n",
    "               )\n",
    "# (by='state',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the star distributions are very similar across states that have substantial number of observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_att_df = count_categories(business_df['attributes'].values, 'dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tip_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tip_df['business_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tip_df['text_len'] = tip_df['text'].apply(lambda x: len(x) if not pd.isnull(x) else 0 ,1)\n",
    "tip_df['business_id_clean'] = tip_df['business_id'].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text length histogram\n",
    "tip_df['text_len'].hist(figsize=(10,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df[business_df['business_id'] =='--9e1ONYQuAa-CB_Rrw7Tw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tip_df[tip_df['business_id'] == '--9e1ONYQuAa-CB_Rrw7Tw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(business_df['business_id'])))\n",
    "print(len(set(tip_df['business_id']))) # tip dataset does not contain all business ids from busines dataset\n",
    "print(len(set(business_df['business_id']) & set(tip_df['business_id'].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# see how many reviews they have vs. tips \n",
    "\n",
    "(business_df.merge(\n",
    "    tip_df.groupby('business_id', as_index=False).agg({'compliment_count': len}),\n",
    "    left_on='business_id',\n",
    "    right_on='business_id',\n",
    "    how='inner'\n",
    "))[['business_id', 'review_count', 'compliment_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tip_df['date'].max())\n",
    "print(tip_df['date'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.loc[0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df['average_stars'].hist(figsize=(10,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df['review_count'].hist(figsize=(10,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Photo Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_df['label'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Another reason for restaurant closure is high rent charges. Adding rent pricing per region could help explain more restaurant closures.\n",
    "- A change in population demographics in certain areas of a city can increase or decrease traffic to some restaurants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources for yelp dataset problems:\n",
    "\n",
    "https://towardsdatascience.com/using-yelp-data-to-predict-restaurant-closure-8aafa4f72ad6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
