{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from boto.s3.connection import S3Connection\n",
    "import boto\n",
    "from boto.s3.key import Key\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "import ast \n",
    "from utils.credentials import access_key, secret_access_key\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0,os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.ldamodel' from '/Users/miraekim/workspace/coursework/persproj/utils/ldamodel.py'>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils.preprocessing as prep\n",
    "import utils.ldamodel as lda\n",
    "import imp\n",
    "imp.reload(lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('s3')\n",
    "\n",
    "conn = boto.s3.connect_to_region('us-east-2',\n",
    "       aws_access_key_id=access_key,\n",
    "       aws_secret_access_key=secret_access_key,\n",
    "       is_secure=True,\n",
    "       calling_format = boto.s3.connection.OrdinaryCallingFormat(),\n",
    "       )\n",
    "\n",
    "bucket = conn.get_bucket('persproj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 143 ms, sys: 64.7 ms, total: 208 ms\n",
      "Wall time: 2.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "food_review_chunks = pd.read_csv('s3://persproj/data/food_review_df.csv', chunksize=1000, iterator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_review_df = pd.concat(food_review_chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = np.load('../models/2020_03_03/bow.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the indices of the dataframe used \n",
    "\n",
    "file = open('../models/2020_03_03/df_index.txt', 'r')\n",
    "file_text = file.read()\n",
    "df_index = [int(x) for x in file_text.split(' ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_review_df_sample = food_review_df.iloc[df_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "lda = LdaModel.load('../models/2020_03_03/model_2020_03_02_01perc.model')\n",
    "\n",
    "loaded_dct = Dictionary.load_from_text('../models/2020_03_03/dictionary.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<WordNetCorpusReader in '/Users/miraekim/nltk_data/corpora/wordnet'>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "\n",
    "def lemmatize(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return lemmatizer.lemmatize(text, pos=get_wordnet_pos(text))\n",
    "\n",
    "\n",
    "def stem(text):\n",
    "    stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "    return stemmer.stem(text)\n",
    "\n",
    "def get_bigrams(docs):\n",
    "\n",
    "    # Add bigrams and trigrams to docs (only ones that appear 20 times or more).\n",
    "    bigram = Phrases(docs, min_count=20)\n",
    "    for idx in range(len(docs)):\n",
    "        for token in bigram[docs[idx]]:\n",
    "            if '_' in token:\n",
    "                # Token is a bigram, add to document.\n",
    "                docs[idx].append(token)\n",
    "    return docs\n",
    "\n",
    "def preprocess_words(text):\n",
    "\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(stem(lemmatize(token)))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_text = '''\n",
    "One of the best Korean hot pots I've had here in San Francisco! Not too long of a wait considering a weekend night, this little joint is always packed to the brim so be sure to sign in on yelp to reserve your spot!\n",
    "\n",
    "We were shown the menu and taken orders before seating so the food came immediately as we sat down which was so convenient. The venue was small and intimate but enough room to fit large parties as most dishes were meant for big groups.\n",
    "\n",
    "'''\n",
    "\n",
    "unseen_text_corpus = preprocess_words(unseen_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "one_doc = loaded_dct.doc2bow(unseen_text_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.047711503), (2, 0.30772126), (4, 0.4017404), (5, 0.233078)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.get_document_topics(one_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.020*\"good\" + 0.020*\"great\" + 0.017*\"servic\" + 0.016*\"order\" + 0.014*\"time\" + 0.014*\"come\" + 0.011*\"burger\" + 0.011*\"like\" + 0.010*\"friend\" + 0.010*\"fri\"'),\n",
       " (1,\n",
       "  '0.013*\"great\" + 0.013*\"good\" + 0.012*\"time\" + 0.010*\"restaur\" + 0.009*\"like\" + 0.008*\"night\" + 0.008*\"go\" + 0.008*\"come\" + 0.007*\"love\" + 0.007*\"best\"'),\n",
       " (2,\n",
       "  '0.016*\"order\" + 0.012*\"time\" + 0.012*\"drink\" + 0.012*\"come\" + 0.010*\"servic\" + 0.010*\"like\" + 0.009*\"wait\" + 0.009*\"go\" + 0.009*\"tabl\" + 0.008*\"say\"'),\n",
       " (3,\n",
       "  '0.020*\"good\" + 0.014*\"pizza\" + 0.014*\"order\" + 0.012*\"chicken\" + 0.012*\"like\" + 0.009*\"sauc\" + 0.008*\"taco\" + 0.008*\"come\" + 0.008*\"great\" + 0.007*\"tast\"'),\n",
       " (4,\n",
       "  '0.011*\"like\" + 0.009*\"room\" + 0.008*\"good\" + 0.008*\"time\" + 0.007*\"great\" + 0.007*\"cream\" + 0.006*\"look\" + 0.006*\"nice\" + 0.006*\"store\" + 0.006*\"friend\"'),\n",
       " (5,\n",
       "  '0.012*\"good\" + 0.011*\"restaur\" + 0.009*\"great\" + 0.008*\"servic\" + 0.008*\"dish\" + 0.007*\"come\" + 0.007*\"order\" + 0.007*\"menu\" + 0.006*\"delici\" + 0.006*\"perfect\"')]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_review(review_id,df):\n",
    "    ind = list(df.review_id.values).index(review_id)\n",
    "    print('Review')\n",
    "    print(df['text'].iloc[ind])\n",
    "    print('\\n')\n",
    "    print('Corpus')\n",
    "    print(sorted([(lda_class.dictionary.get(x[0]), x[1]) for x in lda_class.bow_corpus[ind]], key=lambda x: x[1], reverse=True))\n",
    "    print('\\n')\n",
    "    print('Topics')\n",
    "    print(sorted(lda.get_document_topics(lda_class.bow_corpus[ind]), key=lambda x: x[1], reverse=True))\n",
    "    \n",
    "def get_topic_dist(review_id):\n",
    "    ind = list(food_review_df_sample.review_id.values).index(review_id)\n",
    "    return dict(lda.get_document_topics(bow_corpus[ind]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_topics() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-75bf99c7a7a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLdaMulticore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: get_topics() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "lda.models.LdaMulticore.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.get_document_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3904692         {0: 0.013375101, 2: 0.3011184, 3: 0.6690545}\n",
       "2611438         {0: 0.36692908, 2: 0.06574727, 4: 0.5581931}\n",
       "4531851       {0: 0.71988994, 1: 0.012711138, 2: 0.24739583}\n",
       "822534     {0: 0.27208763, 1: 0.51034594, 2: 0.100129515,...\n",
       "2949890                       {0: 0.36702406, 1: 0.61500376}\n",
       "972433         {1: 0.26047656, 2: 0.01890594, 3: 0.71009094}\n",
       "2413348       {0: 0.012311184, 2: 0.72052485, 3: 0.25155514}\n",
       "38666          {0: 0.020279497, 1: 0.01281158, 4: 0.9438786}\n",
       "4312393    {0: 0.12711872, 1: 0.27447778, 2: 0.19878481, ...\n",
       "1143306          {2: 0.629739, 3: 0.2738738, 4: 0.076821215}\n",
       "dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_review_df_sample[:10].apply(lambda x: get_topic_dist(x['review_id']),1)\n",
    "# food_review_df_sample['topic_dist'] = food_review_df_sample.apply(lambda x: get_topic_dist(x['review_id']),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['relevant_topic'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-73686c7c758a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msurprise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrating_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfood_review_df_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'city'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'relevant_topic'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'review_stars'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/miraekim/miniconda3/envs/main_env/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2932\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2933\u001b[0m             indexer = self.loc._convert_to_indexer(key, axis=1,\n\u001b[0;32m-> 2934\u001b[0;31m                                                    raise_missing=True)\n\u001b[0m\u001b[1;32m   2935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/miraekim/miniconda3/envs/main_env/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1352\u001b[0m                 kwargs = {'raise_missing': True if is_setter else\n\u001b[1;32m   1353\u001b[0m                           raise_missing}\n\u001b[0;32m-> 1354\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1355\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/miraekim/miniconda3/envs/main_env/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         self._validate_read_indexer(keyarr, indexer,\n\u001b[1;32m   1160\u001b[0m                                     \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                                     raise_missing=raise_missing)\n\u001b[0m\u001b[1;32m   1162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/miraekim/miniconda3/envs/main_env/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1250\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'loc'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} not in index\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnot_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m             \u001b[0;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['relevant_topic'] not in index\""
     ]
    }
   ],
   "source": [
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(food_review_df_sample[['city','relevant_topic', 'review_stars']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the famous SVD algorithm.\n",
    "algo = SVD()\n",
    "\n",
    "# Run 5-fold cross-validation and print results.\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
